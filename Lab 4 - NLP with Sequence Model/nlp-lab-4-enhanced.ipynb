{"metadata":{"accelerator":"TPU","colab":{"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8334190,"sourceType":"datasetVersion","datasetId":4949285},{"sourceId":986425,"sourceType":"datasetVersion","datasetId":540042}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dropout, TimeDistributed, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import f1_score","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K41zj5wEm3yP","outputId":"4a43ab5b-fdfa-4e97-8419-cee2c4af84e3","execution":{"iopub.status.busy":"2024-05-06T10:42:22.644126Z","iopub.execute_input":"2024-05-06T10:42:22.645007Z","iopub.status.idle":"2024-05-06T10:42:22.652404Z","shell.execute_reply.started":"2024-05-06T10:42:22.644979Z","shell.execute_reply":"2024-05-06T10:42:22.651506Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/input/glove6b100dtxt","metadata":{"execution":{"iopub.status.busy":"2024-05-06T10:38:36.445161Z","iopub.execute_input":"2024-05-06T10:38:36.445555Z","iopub.status.idle":"2024-05-06T10:38:37.402146Z","shell.execute_reply.started":"2024-05-06T10:38:36.445527Z","shell.execute_reply":"2024-05-06T10:38:37.401127Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"glove.6B.100d.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_data(file_path):\n    with open(file_path, \"r\") as f:\n        lines = f.readlines()\n\n    sentences, labels = [], []\n    sentence, label = [], []\n\n    for line in lines:\n        if line == \"\\n\" or line.startswith(\"-DOCSTART-\"):\n            if sentence and label:\n                sentences.append(sentence)\n                labels.append(label)\n                sentence, label = [], []\n        else:\n            word, _, _, tag = line.strip().split()\n            sentence.append(word.lower())  # Normalize the case\n            label.append(tag)\n\n    return sentences, labels\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T10:38:02.465522Z","iopub.execute_input":"2024-05-06T10:38:02.465805Z","iopub.status.idle":"2024-05-06T10:38:02.473711Z","shell.execute_reply.started":"2024-05-06T10:38:02.465780Z","shell.execute_reply":"2024-05-06T10:38:02.472628Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_file_path = \"/kaggle/input/conll-2003/data/conllpp_train.txt\"\ntest_file_path = \"/kaggle/input/conll-2003/data/conllpp_test.txt\"\n\ntrain_sentences, train_labels = load_data(train_file_path)\ntest_sentences, test_labels = load_data(test_file_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T10:39:04.386271Z","iopub.execute_input":"2024-05-06T10:39:04.387083Z","iopub.status.idle":"2024-05-06T10:39:04.720490Z","shell.execute_reply.started":"2024-05-06T10:39:04.387050Z","shell.execute_reply":"2024-05-06T10:39:04.719486Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained word embeddings\nembeddings_index = {}\nwith open('/kaggle/input/glove6b100dtxt/glove.6B.100d.txt', encoding='utf-8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs","metadata":{"execution":{"iopub.status.busy":"2024-05-06T10:39:06.834456Z","iopub.execute_input":"2024-05-06T10:39:06.835073Z","iopub.status.idle":"2024-05-06T10:39:19.605035Z","shell.execute_reply.started":"2024-05-06T10:39:06.835044Z","shell.execute_reply":"2024-05-06T10:39:19.604005Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Create word-to-index and tag-to-index dictionaries\nwords = list(set([word for sentence in train_sentences + test_sentences for word in sentence]))\nwords.append('ENDPAD')\nn_words = len(words)\ntags = list(set([tag for label in train_labels + test_labels for tag in label]))\nn_tags = len(tags)\n\nword_index = {w: i for i, w in enumerate(words)}\nlabel_index = {t: i for i, t in enumerate(tags)}\n\n# Convert words and tags to sequences of indices\nX_train = [[word_index[w] for w in sentence] for sentence in train_sentences]\nX_train = pad_sequences(maxlen=50, sequences=X_train, padding='post', value=n_words-1)\ny_train = [[label_index[t] for t in label] for label in train_labels]\ny_train = pad_sequences(maxlen=50, sequences=y_train, padding='post', value=label_index['O'])\ny_train = [to_categorical(i, num_classes=n_tags) for i in y_train]\n\nX_test = [[word_index[w] for w in sentence] for sentence in test_sentences]\nX_test = pad_sequences(maxlen=50, sequences=X_test, padding='post', value=n_words-1)\ny_test = [[label_index[t] for t in label] for label in test_labels]\ny_test = pad_sequences(maxlen=50, sequences=y_test, padding='post', value=label_index['O'])\ny_test = [to_categorical(i, num_classes=n_tags) for i in y_test]\n\nmax_len  = 50","metadata":{"execution":{"iopub.status.busy":"2024-05-06T10:42:28.404823Z","iopub.execute_input":"2024-05-06T10:42:28.405198Z","iopub.status.idle":"2024-05-06T10:42:29.479576Z","shell.execute_reply.started":"2024-05-06T10:42:28.405159Z","shell.execute_reply":"2024-05-06T10:42:29.478784Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Create embedding matrix\nembedding_dim = 100\nembedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2024-05-06T10:42:33.784298Z","iopub.execute_input":"2024-05-06T10:42:33.784687Z","iopub.status.idle":"2024-05-06T10:42:33.845465Z","shell.execute_reply.started":"2024-05-06T10:42:33.784658Z","shell.execute_reply":"2024-05-06T10:42:33.844491Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Define model architecture\ninput_layer = Input(shape=(50,))\nembedding_layer = Embedding(len(word_index) + 1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\ndropout_layer = Dropout(0.5)(embedding_layer)\nbidirectional_layer = Bidirectional(LSTM(128, return_sequences=True))(dropout_layer)\noutput_layer = TimeDistributed(Dense(len(label_index), activation='softmax'))(bidirectional_layer)\nmodel = Model(inputs=input_layer, outputs=output_layer)\n\n# Compile model\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T10:42:37.045029Z","iopub.execute_input":"2024-05-06T10:42:37.045875Z","iopub.status.idle":"2024-05-06T10:42:37.247509Z","shell.execute_reply.started":"2024-05-06T10:42:37.045847Z","shell.execute_reply":"2024-05-06T10:42:37.246141Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define model architecture\u001b[39;00m\n\u001b[1;32m      2\u001b[0m input_layer \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m50\u001b[39m,))\n\u001b[0;32m----> 3\u001b[0m embedding_layer \u001b[38;5;241m=\u001b[39m \u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mword_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43membedding_matrix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m(input_layer)\n\u001b[1;32m      4\u001b[0m dropout_layer \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.5\u001b[39m)(embedding_layer)\n\u001b[1;32m      5\u001b[0m bidirectional_layer \u001b[38;5;241m=\u001b[39m Bidirectional(LSTM(\u001b[38;5;241m128\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))(dropout_layer)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:89\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[0;34m(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, embeddings_constraint, mask_zero, lora_rank, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `input_length` is deprecated. Just remove it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim \u001b[38;5;241m=\u001b[39m input_dim\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim \u001b[38;5;241m=\u001b[39m output_dim\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:263\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m     )\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast \u001b[38;5;241m=\u001b[39m autocast\n","\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Embedding: {'weights': [array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.11514   ,  0.16726001, -0.23509   , ..., -0.35883   ,\n         0.38626999, -0.61556   ],\n       [ 0.18971001, -0.017413  ,  0.62576002, ..., -0.35029   ,\n         0.034271  ,  0.82238001],\n       ...,\n       [-0.075529  , -0.27406001, -0.34755999, ...,  0.19689   ,\n        -0.22531   , -0.92199999],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ]])]}"],"ename":"ValueError","evalue":"Unrecognized keyword arguments passed to Embedding: {'weights': [array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.11514   ,  0.16726001, -0.23509   , ..., -0.35883   ,\n         0.38626999, -0.61556   ],\n       [ 0.18971001, -0.017413  ,  0.62576002, ..., -0.35029   ,\n         0.034271  ,  0.82238001],\n       ...,\n       [-0.075529  , -0.27406001, -0.34755999, ...,  0.19689   ,\n        -0.22531   , -0.92199999],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ]])]}","output_type":"error"}]},{"cell_type":"code","source":"# Train model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3)\nmodel.fit(X_train, np.array(y_train), validation_split=0.1, batch_size=32, epochs=10, callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2024-05-06T10:38:03.881451Z","iopub.status.idle":"2024-05-06T10:38:03.881754Z","shell.execute_reply.started":"2024-05-06T10:38:03.881604Z","shell.execute_reply":"2024-05-06T10:38:03.881616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Evaluate model\n# y_pred = model.predict(X_test)\n# y_pred = np.argmax(y_pred, axis=-1)\n# y_test_labels = [[tags[i] for i in row] for row in np.argmax(y_test, axis=-1)]\n# y_pred_labels = [[tags[i] for i in row] for row in y_pred]\n# f1 = f1_score(y_test_labels, y_pred_labels, average='weighted')\n# print(\"F1-score: {:.2f}\".format(f1))","metadata":{"execution":{"iopub.status.busy":"2024-05-06T10:38:03.883450Z","iopub.status.idle":"2024-05-06T10:38:03.883773Z","shell.execute_reply.started":"2024-05-06T10:38:03.883617Z","shell.execute_reply":"2024-05-06T10:38:03.883630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n# Evaluate model\ny_pred = model.predict(X_test)\ny_pred = np.argmax(y_pred, axis=-1)\ny_test_labels = [[tags[i] for i in row] for row in np.argmax(y_test, axis=-1)]\ny_pred_labels = [[tags[i] for i in row] for row in y_pred]\n\n\n# Print classification report\nreport = classification_report(y_test_labels_flat, y_pred_labels_flat)\nprint(report)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQZEwFRXndWq","outputId":"d0b9820d-f50d-4435-b2ed-454b0ea40191","execution":{"iopub.status.busy":"2024-05-06T10:38:03.884810Z","iopub.status.idle":"2024-05-06T10:38:03.885113Z","shell.execute_reply.started":"2024-05-06T10:38:03.884963Z","shell.execute_reply":"2024-05-06T10:38:03.884975Z"},"trusted":true},"execution_count":null,"outputs":[]}]}